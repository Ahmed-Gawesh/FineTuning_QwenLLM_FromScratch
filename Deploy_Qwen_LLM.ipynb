{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBWkAHfHcIMj",
        "outputId": "c2849d5f-c890-4ec9-a49e-daaddc462911"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install json_repair"
      ],
      "metadata": {
        "id": "umi0I01Ecntc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "import json\n",
        "import json_repair"
      ],
      "metadata": {
        "id": "fjPo78nacemW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator:\n",
        "    def __init__(self, model, tokenizer):\n",
        "        self.model, self.tokenizer = model, tokenizer\n",
        "        self.mask = None\n",
        "\n",
        "    def generate(self, messages: list, max_new_tokens: int = 2000, temperature: float = 0.1):\n",
        "        def logits_processor(token_ids, logits):\n",
        "            if self.mask is None:\n",
        "                token_ids = torch.arange(logits.size(-1))\n",
        "                decoded_tokens = self.tokenizer.batch_decode(token_ids.unsqueeze(1), skip_special_tokens=True)\n",
        "                self.mask = torch.tensor([\n",
        "                    any(0x4E00 <= ord(c) <= 0x9FFF or 0x3400 <= ord(c) <= 0x4DBF or 0xF900 <= ord(c) <= 0xFAFF for c in token)\n",
        "                    for token in decoded_tokens\n",
        "                ])\n",
        "            logits[:, self.mask] = -float(\"inf\")\n",
        "            return logits\n",
        "\n",
        "        text = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "        model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.model.device)\n",
        "        generated_ids = self.model.generate(\n",
        "            **model_inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=temperature,\n",
        "            logits_processor=[logits_processor]\n",
        "        )\n",
        "        generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)]\n",
        "        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "        return response"
      ],
      "metadata": {
        "id": "TpksRAkecItb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "adapter_path = \"/gdrive/MyDrive/FineTuning_fromScratch/models\"\n",
        "model = AutoModelForCausalLM.from_pretrained(base_model_id, device_map=\"auto\", torch_dtype=None)\n",
        "model.load_adapter(adapter_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
        "llm = Generator(model, tokenizer)"
      ],
      "metadata": {
        "id": "wF9k59wWcIvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_input(text, task):\n",
        "    if task == \"Extraction Details\":\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\\n\".join([\n",
        "                    \"You are an NLP data parser.\",\n",
        "                    \"You will be provided by an Arabic text associated with a Pydantic scheme.\",\n",
        "                    \"Generate the output in the same story language.\",\n",
        "                    \"You have to extract JSON details from text according the Pydantic details.\",\n",
        "                    \"Extract details as mentioned in text.\",\n",
        "                    \"Do not generate any introduction or conclusion.\"\n",
        "                ])\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"\\n\".join([\n",
        "                    \"## Story:\",\n",
        "                    text.strip(),\n",
        "                    \"\",\n",
        "                    \"## Pydantic Details:\",\n",
        "                    json.dumps({\n",
        "                        \"type\": \"object\",\n",
        "                        \"properties\": {\n",
        "                            \"story_title\": {\"type\": \"string\", \"minLength\": 5, \"maxLength\": 300},\n",
        "                            \"story_keywords\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"minItems\": 1},\n",
        "                            \"story_summary\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"minItems\": 1, \"maxItems\": 5},\n",
        "                            \"story_category\": {\"type\": \"string\", \"enum\": [\"politics\", \"sports\", \"art\", \"technology\", \"economy\", \"health\", \"entertainment\", \"science\", \"not_specified\"]},\n",
        "                            \"story_entities\": {\"type\": \"array\", \"items\": {\n",
        "                                \"type\": \"object\",\n",
        "                                \"properties\": {\n",
        "                                    \"entity_value\": {\"type\": \"string\"},\n",
        "                                    \"entity_type\": {\"type\": \"string\", \"enum\": [\"person-male\", \"person-female\", \"location\", \"organization\", \"event\", \"time\", \"quantity\", \"money\", \"product\", \"law\", \"disease\", \"artifact\", \"not_specified\"]}\n",
        "                                },\n",
        "                                \"required\": [\"entity_value\", \"entity_type\"]\n",
        "                            }, \"minItems\": 1, \"maxItems\": 10}\n",
        "                        },\n",
        "                        \"required\": [\"story_title\", \"story_keywords\", \"story_summary\", \"story_category\", \"story_entities\"]\n",
        "                    }, ensure_ascii=False),\n",
        "                    \"\",\n",
        "                    \"## Story Details:\",\n",
        "                    \"```json\"\n",
        "                ])\n",
        "            }\n",
        "        ]\n",
        "    elif task == \"Translation\":\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\\n\".join([\n",
        "                    \"You are a professional translator.\",\n",
        "                    \"You will be provided by an Arabic text.\",\n",
        "                    \"You have to translate the text into the `Targeted Language`.\",\n",
        "                    \"Follow the provided Scheme to generate a JSON\",\n",
        "                    \"Do not generate any introduction or conclusion.\"\n",
        "                ])\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"\\n\".join([\n",
        "                    \"## Story:\",\n",
        "                    text.strip(),\n",
        "                    \"\",\n",
        "                    \"## Pydantic Details:\",\n",
        "                    json.dumps({\n",
        "                        \"type\": \"object\",\n",
        "                        \"properties\": {\n",
        "                            \"translated_title\": {\"type\": \"string\", \"minLength\": 5, \"maxLength\": 300},\n",
        "                            \"translated_content\": {\"type\": \"string\", \"minLength\": 5}\n",
        "                        },\n",
        "                        \"required\": [\"translated_title\", \"translated_content\"]\n",
        "                    }, ensure_ascii=False),\n",
        "                    \"\",\n",
        "                    \"## Targeted Language:\",\n",
        "                    \"English\",\n",
        "                    \"\",\n",
        "                    \"## Translated Story:\",\n",
        "                    \"```json\"\n",
        "                ])\n",
        "            }\n",
        "        ]\n",
        "    else:\n",
        "        return \"Chosse your mission: Translation or Extraction Details\"\n",
        "\n",
        "    response = llm.generate(messages)\n",
        "    try:\n",
        "        return json.dumps(json_repair.loads(response), ensure_ascii=False, indent=2)\n",
        "    except:\n",
        "        return response\n",
        "\n"
      ],
      "metadata": {
        "id": "N31_IFuecIyQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface = gr.Interface(\n",
        "    fn=process_input,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Text (Arabic)\", lines=10),\n",
        "        gr.Dropdown(choices=[\"Extraction Details\", \"Translation\"], label=\"Task\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Result\"),\n",
        "    title=\"News Analyst\",\n",
        "    description=\"Enter text in Arabic and choose a task (extract details or translation) to get the result.\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "i7GLxSdlT8hF",
        "outputId": "4c072def-9123-4d3f-d046-417e17271f05"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5d517a078cce906801.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5d517a078cce906801.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V_TNLI0_cI9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0qQRkH53cJAy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}